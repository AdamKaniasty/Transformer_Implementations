{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_json('data/trainmodel.json')\n",
    "validate = pd.read_json('data/val.json')\n",
    "\n",
    "train['answers'] = train['answers'].apply(lambda x: x[0])\n",
    "validate['answers'] = validate['answers'].apply(lambda x: x[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T22:31:06.895258619Z",
     "start_time": "2024-04-09T22:31:06.795383810Z"
    }
   },
   "id": "a388de46bf01c410",
   "execution_count": 95
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "         qId        answers                                              qText\n0  wqr000001  Padmé Amidala  what character did natalie portman play in sta...\n1  wqr000002  New York City                      what state does selena gomez?\n2  wqr000003        Bahamas        what country is the grand bahama island in?\n3  wqr000005    Denethor II  what character did john noble play in lord of ...\n4  wqr000006  Chicago Bulls                     who does joakim noah play for?",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qId</th>\n      <th>answers</th>\n      <th>qText</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>wqr000001</td>\n      <td>Padmé Amidala</td>\n      <td>what character did natalie portman play in sta...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>wqr000002</td>\n      <td>New York City</td>\n      <td>what state does selena gomez?</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>wqr000003</td>\n      <td>Bahamas</td>\n      <td>what country is the grand bahama island in?</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>wqr000005</td>\n      <td>Denethor II</td>\n      <td>what character did john noble play in lord of ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>wqr000006</td>\n      <td>Chicago Bulls</td>\n      <td>who does joakim noah play for?</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T22:31:06.989729556Z",
     "start_time": "2024-04-09T22:31:06.942593224Z"
    }
   },
   "id": "fd83109d27cae1db",
   "execution_count": 96
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "questions = train['qText'].values\n",
    "answers = train['answers'].values\n",
    "questions_val = validate['qText'].values\n",
    "answers_val = validate['answers'].values\n",
    "\n",
    "questions_text = \" \".join(list(questions))\n",
    "answers_text = \" \".join(list(answers))\n",
    "questions_val_text = \" \".join(list(questions_val))\n",
    "answers_val_text = \" \".join(list(answers_val))\n",
    "\n",
    "full_text = \"$\" + questions_text + \" \" + answers_text + \" \" + questions_val_text + \" \" + answers_val_text + \"@\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T22:31:07.177776704Z",
     "start_time": "2024-04-09T22:31:06.991462742Z"
    }
   },
   "id": "25c796eafcfdf7a0",
   "execution_count": 97
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "vocab_size = len(set(full_text))\n",
    "encoder_map = {'$': 0, '@': 1}\n",
    "decoder_map = {0: '$', 1: '@'}\n",
    "unique_chars = set(full_text)\n",
    "\n",
    "for i, c in enumerate(unique_chars.difference({'$', '@'}), start=2):\n",
    "    encoder_map[c] = i\n",
    "    decoder_map[i] = c\n",
    "\n",
    "encode = lambda x: [encoder_map[c] for c in x]\n",
    "decode = lambda x: ''.join([decoder_map[i] for i in x])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T22:31:07.180596948Z",
     "start_time": "2024-04-09T22:31:07.078894636Z"
    }
   },
   "id": "56d610e0a443e539",
   "execution_count": 98
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "([0, 0, 0, 94, 92, 23, 47, 26, 23, 47, 50, 63, 51, 16, 1], '$$$Test string@')"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"$$$Test string@\"), decode(encode(\"$$$Test string@\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T22:31:07.268293010Z",
     "start_time": "2024-04-09T22:31:07.206592297Z"
    }
   },
   "id": "d2d306d750fdb8c",
   "execution_count": 99
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(2115)\n",
    "batch_size = 16\n",
    "seq_len = 48\n",
    "n_embed = 32\n",
    "num_heads = 8\n",
    "\n",
    "\n",
    "def pad_sequences(sequences, seq_len):\n",
    "    padded_sequences = [[0] * (seq_len - len(seq)) + seq for seq in sequences]\n",
    "    return padded_sequences\n",
    "\n",
    "\n",
    "def truncate_sequences(sequences, max_len):\n",
    "    truncated_sequences = [seq[:max_len] for seq in sequences]\n",
    "    return truncated_sequences\n",
    "\n",
    "\n",
    "def get_batches(questions, answers):\n",
    "    idx = torch.randint(0, len(questions), (batch_size,))\n",
    "    batch_questions = questions[idx].tolist()\n",
    "    batch_answers = answers[idx].tolist()\n",
    "\n",
    "    encoded_questions = [encode(q)[:-1] for q in batch_questions]\n",
    "    encoded_answers = [encode(a)[:-1] for a in batch_answers]\n",
    "\n",
    "    y_questions = [encode(q)[1:] for q in batch_questions]\n",
    "    y_answers = [encode(a)[1:] for a in batch_answers]\n",
    "\n",
    "    encoded_questions = truncate_sequences(encoded_questions, seq_len)\n",
    "    encoded_answers = truncate_sequences(encoded_answers, seq_len)\n",
    "    y_questions = truncate_sequences(y_questions, seq_len)\n",
    "    y_answers = truncate_sequences(y_answers, seq_len)\n",
    "\n",
    "    x = pad_sequences(encoded_questions, seq_len)\n",
    "    y = pad_sequences(y_questions, seq_len)\n",
    "    x_ans = pad_sequences(encoded_answers, seq_len)\n",
    "    y_ans = pad_sequences(y_answers, seq_len)\n",
    "\n",
    "    x, y, x_ans, y_ans = map(lambda seqs: torch.tensor(seqs), [x, y, x_ans, y_ans])\n",
    "\n",
    "    return x, y, x_ans, y_ans\n",
    "\n",
    "\n",
    "x, y, x_ans, y_ans = get_batches(questions, answers)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T22:31:07.370465268Z",
     "start_time": "2024-04-09T22:31:07.269236107Z"
    }
   },
   "id": "38603cf7231ae894",
   "execution_count": 100
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from EncoderDecoder.layers.Decoder.Decoder import Decoder\n",
    "from EncoderDecoder.layers.Encoder.Encoder import Encoder\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def generate_mask(src, tgt):\n",
    "    src_mask = (src != 0).unsqueeze(1)\n",
    "    tgt_mask = (tgt != 0).unsqueeze(1)\n",
    "    seq_length = tgt.size(1)\n",
    "    nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n",
    "    tgt_mask = tgt_mask & nopeak_mask\n",
    "    return src_mask, tgt_mask\n",
    "\n",
    "\n",
    "class EncoderDecoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(vocab_size, n_embed, num_heads, seq_len)\n",
    "        self.decoder = Decoder(vocab_size, n_embed, num_heads, seq_len)\n",
    "\n",
    "    def forward(self, prompt, response, targets=None):\n",
    "        src_mask, tgt_mask = generate_mask(prompt, response)\n",
    "        k, v = self.encoder(prompt, src_mask)\n",
    "        x, loss = self.decoder(response, k, v, targets, tgt_mask)\n",
    "        return x, loss\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_mask(src, tgt):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = tgt.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n",
    "        tgt_mask = tgt_mask & nopeak_mask\n",
    "        return src_mask, tgt_mask\n",
    "\n",
    "    def generate(self, prompt, idx, n):\n",
    "        for _ in range(n):\n",
    "            idx_crop = idx[:, -seq_len:]\n",
    "            logits, _ = self(idx_crop, prompt)\n",
    "            logits = logits[:, -1, :]\n",
    "            p = F.softmax(logits, dim=-1)\n",
    "            next_token = torch.multinomial(p, num_samples=1)\n",
    "            if next_token == 1 or next_token == [1]:\n",
    "                return idx\n",
    "            idx = torch.cat((idx, next_token), dim=1)\n",
    "        return idx"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T22:31:07.525611887Z",
     "start_time": "2024-04-09T22:31:07.377380838Z"
    }
   },
   "id": "3b721e4ed3077d66",
   "execution_count": 101
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss(model, eval_iters=200):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            x, y, x_ans, y_ans = get_batches(questions, answers) if split == 'train' else get_batches(questions_val,\n",
    "                                                                                                      answers_val)\n",
    "            logits, loss = model(x, y, x_ans)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T22:31:07.644895915Z",
     "start_time": "2024-04-09T22:31:07.528920891Z"
    }
   },
   "id": "98b115d0c225d802",
   "execution_count": 102
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, train loss: 4.797, val loss: 4.793\n",
      "Iter 10, train loss: 3.881, val loss: 3.905\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "def notify_end_of_cell(message=\"Cell execution completed!\"):\n",
    "    os.system(f'notify-send \"Jupyter Cell Notification\" \"{message}\"')\n",
    "\n",
    "\n",
    "m = EncoderDecoder()\n",
    "optimizer = torch.optim.Adam(m.parameters(), lr=0.0003)\n",
    "history = []\n",
    "eval_interval = 10\n",
    "max_iter = 50\n",
    "for iter in range(max_iter):\n",
    "    if iter % eval_interval == 0:\n",
    "        losses = estimate_loss(m)\n",
    "        history.append((iter, losses))\n",
    "        print(f'Iter {iter}, train loss: {losses[\"train\"]:.3f}, val loss: {losses[\"val\"]:.3f}')\n",
    "\n",
    "    x, y, x_ans, y_ans = get_batches(questions, answers)\n",
    "    logits, loss = m(x, y, x_ans)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "notify_end_of_cell()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-04-09T22:31:07.646913447Z"
    }
   },
   "id": "873ab0ac2df82323",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(25, 5))\n",
    "\n",
    "x = [h[0] for h in history]\n",
    "y = [h[1]['train'] for h in history]\n",
    "y_val = [h[1]['val'] for h in history]\n",
    "plt.plot(x, y, label='train')\n",
    "plt.plot(x, y_val, label='val')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "11094736f4f7ede6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "prompt = 'where is Perpignan located?'\n",
    "prompt = torch.tensor(truncate_sequences([encode(prompt)], seq_len))\n",
    "idx = torch.ones((1, 1), dtype=torch.long)\n",
    "print(decode(m.generate(prompt, idx, 100)[0].tolist()))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c266e5c673669841",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.save(m.state_dict(), './models/parallel_checkpoints_64_2.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "21360823cf1ce48f",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
